{"data":[{"id":"sao10k/l3.1-70b-hanami-x1","name":"Sao10K: Llama 3.1 70B Hanami x1","created":1736302854,"description":"This is [Sao10K](/sao10k)'s experiment over [Euryale v2.2](/sao10k/l3.1-euryale-70b).","context_length":16000,"architecture":{"modality":"text->text","tokenizer":"Llama3","instruct_type":null},"pricing":{"prompt":"0.000003","completion":"0.000003","image":"0","request":"0"},"top_provider":{"context_length":16000,"max_completion_tokens":null,"is_moderated":false},"per_request_limits":null},{"id":"deepseek/deepseek-chat","name":"DeepSeek V3","created":1735241320,"description":"DeepSeek-V3 is the latest model from the DeepSeek team, building upon the instruction following and coding abilities of the previous versions. Pre-trained on nearly 15 trillion tokens, the reported evaluations reveal that the model outperforms other open-source models and rivals leading closed-source models. For model details, please visit [the DeepSeek-V3 repo](https://github.com/deepseek-ai/DeepSeek-V3) for more information.","context_length":64000,"architecture":{"modality":"text->text","tokenizer":"Other","instruct_type":null},"pricing":{"prompt":"0.00000014","completion":"0.00000028","image":"0","request":"0"},"top_provider":{"context_length":64000,"max_completion_tokens":8192,"is_moderated":false},"per_request_limits":null},{"id":"qwen/qvq-72b-preview","name":"Qwen: QvQ 72B Preview","created":1735088567,"description":"QVQ-72B-Preview is an experimental research model developed by the [Qwen](/qwen) team, focusing on enhancing visual reasoning capabilities.\n\n## Performance\n\n|                | **QVQ-72B-Preview** | o1-2024-12-17 | gpt-4o-2024-05-13 | Claude3.5 Sonnet-20241022 | Qwen2VL-72B |\n|----------------|-----------------|---------------|-------------------|----------------------------|-------------|\n| MMMU(val)      | 70.3            | 77.3          | 69.1              | 70.4                       | 64.5        |\n| MathVista(mini) | 71.4            | 71.0          | 63.8              | 65.3                       | 70.5        |\n| MathVision(full)   | 35.9            | –             | 30.4              | 35.6                       | 25.9        |\n| OlympiadBench  | 20.4            | –             | 25.9              | –                          | 11.2        |\n\n\n## Limitations\n\n1. **Language Mixing and Code-Switching:** The model might occasionally mix different languages or unexpectedly switch between them, potentially affecting the clarity of its responses.\n2. **Recursive Reasoning Loops:**  There's a risk of the model getting caught in recursive reasoning loops, leading to lengthy responses that may not even arrive at a final answer.\n3. **Safety and Ethical Considerations:** Robust safety measures are needed to ensure reliable and safe performance. Users should exercise caution when deploying this model.\n4. **Performance and Benchmark Limitations:** Despite the improvements in visual reasoning, QVQ doesn't entirely replace the capabilities of [Qwen2-VL-72B](/qwen/qwen-2-vl-72b-instruct). During multi-step visual reasoning, the model might gradually lose focus on the image content, leading to hallucinations. Moreover, QVQ doesn't show significant improvement over [Qwen2-VL-72B](/qwen/qwen-2-vl-72b-instruct) in basic recognition tasks like identifying people, animals, or plants.\n\nNote: Currently, the model only supports single-round dialogues and image outputs. It does not support video inputs.","context_length":128000,"architecture":{"modality":"text+image->text","tokenizer":"Qwen","instruct_type":null},"pricing":{"prompt":"0.00000025","completion":"0.0000005","image":"0","request":"0"},"top_provider":{"context_length":128000,"max_completion_tokens":4096,"is_moderated":false},"per_request_limits":null},{"id":"google/gemini-2.0-flash-thinking-exp:free","name":"Google: Gemini 2.0 Flash Thinking Experimental (free)","created":1734650026,"description":"Gemini 2.0 Flash Thinking Mode is an experimental model that's trained to generate the \"thinking process\" the model goes through as part of its response. As a result, Thinking Mode is capable of stronger reasoning capabilities in its responses than the [base Gemini 2.0 Flash model](/google/gemini-2.0-flash-exp).","context_length":40000,"architecture":{"modality":"text+image->text","tokenizer":"Gemini","instruct_type":null},"pricing":{"prompt":"0","completion":"0","image":"0","request":"0"},"top_provider":{"context_length":40000,"max_completion_tokens":8000,"is_moderated":false},"per_request_limits":null},{"id":"sao10k/l3.3-euryale-70b","name":"Sao10K: Llama 3.3 Euryale 70B","created":1734535928,"description":"Euryale L3.3 70B is a model focused on creative roleplay from [Sao10k](https://ko-fi.com/sao10k). It is the successor of [Euryale L3 70B v2.2](/models/sao10k/l3-euryale-70b).","context_length":16384,"architecture":{"modality":"text->text","tokenizer":"Llama3","instruct_type":"llama3"},"pricing":{"prompt":"0.0000015","completion":"0.0000015","image":"0","request":"0"},"top_provider":{"context_length":16384,"max_completion_tokens":null,"is_moderated":false},"per_request_limits":null}]}
